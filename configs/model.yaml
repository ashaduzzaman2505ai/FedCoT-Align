model:
  name: "google/flan-t5-small"
  d_model: 512
  num_layers: 8
  dropout: 0.1
  max_source_length: 512
  max_target_length: 128

heads:
  verifier:
    hidden_dim: 256
    dropout: 0.1
  projector:
    projection_dim: 128  # Latent CoT alignment space

loss_weights:
  lambda_verifier: 0.5   # λ1
  lambda_align: 0.1      # λ2 (Initial value, tuned in ablations)

optimizer:
  lr: 5e-5               # Standard for fine-tuning small T5
  weight_decay: 0.01
  warmup_steps: 100